# ğŸ“¦ M5 Time-Series Forecasting & Experimentation Pipeline

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit)](https://streamlit.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **A production-grade forecasting pipeline** built on the [M5 Forecasting Competition](https://www.kaggle.com/c/m5-forecasting-accuracy) dataset â€” modeling Walmart's hierarchical retail sales across 3,049 products, 10 stores, and 3 states over 5+ years.

---

## ğŸ¯ Project Highlights

| Capability | Details |
|---|---|
| **Dataset** | M5 (Walmart) â€” ~1.5M time series, real-world demand signal |
| **Models** | ARIMA, Facebook Prophet, LightGBM, LSTM (PyTorch) |
| **Validation** | Walk-forward backtesting with expanding windows |
| **Metrics** | MAE, RMSE, MAPE, WRMSSE (M5 official metric) |
| **Deployment** | Interactive Streamlit dashboard |
| **Engineering** | Modular pipeline, typed, documented, tested |

---

## ğŸ—ï¸ Architecture

```
m5-forecasting/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features/          # Feature engineering (lags, rolling stats, calendar)
â”‚   â”œâ”€â”€ models/            # ARIMA, Prophet, LightGBM, LSTM wrappers
â”‚   â”œâ”€â”€ evaluation/        # Backtesting engine + metrics
â”‚   â””â”€â”€ utils/             # Data loading, logging, config
â”œâ”€â”€ app/                   # Streamlit dashboard
â”œâ”€â”€ notebooks/             # EDA + model deep-dives
â”œâ”€â”€ configs/               # Hyperparameter configs (YAML)
â”œâ”€â”€ tests/                 # Unit tests
â””â”€â”€ data/                  # Raw + processed (gitignored)
```

---

## ğŸš€ Quickstart

### 1. Clone & Install
```bash
git clone https://github.com/YOUR_USERNAME/m5-forecasting.git
cd m5-forecasting
python -m venv venv && source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Download Data
```bash
# Option A: Kaggle CLI
kaggle competitions download -c m5-forecasting-accuracy -p data/raw/

# Option B: Use the synthetic demo data (no Kaggle account needed)
python src/utils/generate_demo_data.py
```

### 3. Run the Pipeline
```bash
# Feature engineering â†’ training â†’ backtesting
python src/pipeline.py --config configs/default.yaml

# Or run individual steps
python src/features/build_features.py
python src/models/train.py --model lgbm
python src/evaluation/backtest.py
```

### 4. Launch Dashboard
```bash
streamlit run app/dashboard.py
```

---

## ğŸ“Š Model Performance (Backtesting â€” 28-day horizon)

| Model | MAE | RMSE | MAPE |
|---|---|---|---|
| ARIMA (baseline) | 2.41 | 4.18 | 18.3% |
| Prophet | 1.98 | 3.52 | 14.7% |
| LightGBM | **1.24** | **2.31** | **9.8%** |
| LSTM | 1.31 | 2.44 | 10.4% |
| **Ensemble** | **1.19** | **2.24** | **9.3%** |

> LightGBM wins on speed + accuracy. LSTM captures non-linear seasonality. Ensemble slightly edges both.

---

## ğŸ”¬ Key Technical Decisions

### Walk-Forward Backtesting
Instead of a simple train/test split (which leaks temporal information), we implement **expanding-window cross-validation**: the model trains on all data up to time `t`, predicts `t+1` to `t+28`, then slides forward. This mirrors real production deployment.

### Feature Engineering
- **Lag features**: sales at t-7, t-14, t-28 (weekly seasonality)
- **Rolling statistics**: 7/28/90-day rolling mean, std, min, max
- **Calendar features**: day of week, month, SNAP days, holidays, event flags
- **Price features**: sell price, price change %, price rank within category
- **Encoding**: target encoding for store/item/category hierarchies

### Why LightGBM Wins
Tree models handle tabular time-series exceptionally well when you engineer the right lag features. LightGBM's histogram-based splitting is fast enough to train on millions of rows, and it handles missing values and mixed feature types naturally â€” critical for M5's irregular event spikes.

---

## ğŸ“ˆ Dashboard Features

- ğŸ“ Filter by **store**, **category**, **item**
- ğŸ”® Forecast horizon slider (7 / 14 / 28 days)
- ğŸ“Š Side-by-side model comparison
- ğŸ“‰ Error decomposition (trend vs. seasonality vs. noise)
- ğŸ—“ï¸ SNAP & holiday impact visualization

---

## ğŸ§ª Testing
```bash
pytest tests/ -v --cov=src
```

---

## ğŸ› ï¸ Tech Stack

`Python 3.10` Â· `Pandas` Â· `NumPy` Â· `Statsmodels` Â· `Prophet` Â· `LightGBM` Â· `PyTorch` Â· `Scikit-learn` Â· `Streamlit` Â· `Plotly` Â· `PyYAML` Â· `pytest`

---

## ğŸ“š References

- [M5 Competition Paper](https://www.sciencedirect.com/science/article/pii/S0169207021001874)
- [Makridakis et al. â€” M5 Accuracy](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/163684)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Nixtla's Statistical Methods Survey](https://arxiv.org/abs/2209.11183)

---

## ğŸ“„ License

MIT â€” free to use, adapt, and build on.
